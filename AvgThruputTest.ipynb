{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average throughput test\n",
    "\n",
    "Use this notebook to test out an alternate approach to calculating the event throughput by using the average time to process an event rather than the total number of events and the total time. This measurement should be more robust against idle core fluctuations at the end of the event processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the data\n",
    "\n",
    "Let's start with some job results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.prep import parse_job_results, load_job_results\n",
    "from utils.timing import get_throughput, get_evloop_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgThruputTest.ipynb              \u001b[34mresults_aibuild_1mu_2016_07_22\u001b[m\u001b[m/\r\n",
      "G4HiveAna_1muon.ipynb             \u001b[34mresults_aibuild_tt_2016_05_21\u001b[m\u001b[m/\r\n",
      "G4HiveAna_1muon_knl.ipynb         \u001b[34mresults_aibuild_tt_2016_05_25\u001b[m\u001b[m/\r\n",
      "G4HiveAna_ttbar.ipynb             \u001b[34mresults_aibuild_tt_2016_05_31\u001b[m\u001b[m/\r\n",
      "README.md                         \u001b[34mresults_cori_1mu_2016_05_17\u001b[m\u001b[m/\r\n",
      "TestPickle.ipynb                  \u001b[34mresults_endeavour_1mu\u001b[m\u001b[m/\r\n",
      "ThroughputTable.ipynb             \u001b[34mresults_endeavour_1mu_2016_08_06\u001b[m\u001b[m/\r\n",
      "Untitled.ipynb                    \u001b[34mresults_endeavour_1mu_2016_08_14\u001b[m\u001b[m/\r\n",
      "\u001b[31mparseResults.py\u001b[m\u001b[m*                  test.pickle\r\n",
      "\u001b[34mresults_aibuild_1mu_2016_05_19\u001b[m\u001b[m/   \u001b[34mutils\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_file = 'results_aibuild_1mu_2016_07_22/results.pickle'\n",
    "job_results = load_job_results(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<utils.prep.JobResult at 0x10dc79f98>,\n",
       " <utils.prep.JobResult at 0x10e846908>,\n",
       " <utils.prep.JobResult at 0x10e846ba8>,\n",
       " <utils.prep.JobResult at 0x10e846e48>,\n",
       " <utils.prep.JobResult at 0x10e855128>,\n",
       " <utils.prep.JobResult at 0x10e8554a8>,\n",
       " <utils.prep.JobResult at 0x10e855828>,\n",
       " <utils.prep.JobResult at 0x10e855ba8>,\n",
       " <utils.prep.JobResult at 0x10e855f28>,\n",
       " <utils.prep.JobResult at 0x10e8582e8>,\n",
       " <utils.prep.JobResult at 0x10e858668>,\n",
       " <utils.prep.JobResult at 0x10e8589e8>,\n",
       " <utils.prep.JobResult at 0x10e858d68>,\n",
       " <utils.prep.JobResult at 0x111f4b128>,\n",
       " <utils.prep.JobResult at 0x111f4b4a8>,\n",
       " <utils.prep.JobResult at 0x111f4b828>,\n",
       " <utils.prep.JobResult at 0x111f4bba8>,\n",
       " <utils.prep.JobResult at 0x111f4bf28>,\n",
       " <utils.prep.JobResult at 0x111f4e2e8>,\n",
       " <utils.prep.JobResult at 0x111f4e668>,\n",
       " <utils.prep.JobResult at 0x111f4e9e8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick test with single thread\n",
    "\n",
    "Can I calculate the throughput on a single thread. Compare to my existing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000\n",
      "[('starts', '<i8'), ('ends', '<i8'), ('algs', '<U15'), ('tids', '<i4'), ('slots', '<i4'), ('events', '<i4')]\n"
     ]
    }
   ],
   "source": [
    "j0 = job_results[0]\n",
    "print(j0.nThread, j0.nEvent)\n",
    "print(j0.timeline_results.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1469166623831742318, 0) (1469166623832310076, 0) (1469166623865992343, 0)\n",
      " (1469166628370060150, 0) (1469166628567813934, 0) (1469166628567847419, 0)\n",
      " (1469166628570491966, 1) (1469166628570551335, 1) (1469166628570739322, 1)\n",
      " (1469166628928540478, 1)]\n"
     ]
    }
   ],
   "source": [
    "starts_events = j0.timeline_results[['starts', 'events']]\n",
    "print(starts_events[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1469166623831742318, 0), (1469166623832310076, 0),\n",
       "       (1469166623865992343, 0), ..., (1469167346610054353, 999),\n",
       "       (1469167346611805687, 999), (1469167346611830146, 999)], \n",
       "      dtype=[('starts', '<i8'), ('events', '<i4')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "We need to put the timeline results into a way that makes this calculation easy. Events are processed within a slot. A slot should only process one event at a time, but it can be executing algorithms for that event on concurrent threads. Still, I think I could loop through a slot and identify when an event begins. The time between begins is the event period. The event rate is the reciprocal of the average period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000\n"
     ]
    }
   ],
   "source": [
    "# Try to get the start times and event numbers of some timeline results\n",
    "j = job_results[3]\n",
    "print(j.nThread, j.nEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slots = j.timeline_results['slots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slots == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timeline_slot_idxs(job, slot):\n",
    "    return job.timeline_results['slots'] == slot\n",
    "\n",
    "def get_all_timeline_slot_idxs(job):\n",
    "    slots = np.unique(job.timeline_results['slots'])\n",
    "    return [get_timeline_slot_idxs(job, slot) for slot in slots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = get_all_timeline_slot_idxs(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ True,  True,  True, ..., False,  True, False], dtype=bool),\n",
       " array([False, False, False, ..., False, False,  True], dtype=bool),\n",
       " array([False, False, False, ..., False, False, False], dtype=bool),\n",
       " array([False, False, False, ...,  True, False, False], dtype=bool)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpler calculation by thread\n",
    "Let's do this a little simpler. Calculate the average throughput per thread by summing all events and individual thread times, then scale this up by the number of threads to get an average throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timeline_duration(timeline, start_time=None):\n",
    "    \"\"\"Calculation total duration of a set of timeline results\"\"\"\n",
    "    if start_time is None:\n",
    "        start_time = timeline['starts'].min()\n",
    "    end_time = timeline['ends'].max()\n",
    "    return (end_time - start_time)*1e-9\n",
    "\n",
    "def get_timelines_by_tid(timeline):\n",
    "    \"\"\"Get dictionary of (tid, timeline)\"\"\"\n",
    "    tids = timeline['tids']\n",
    "    unique_tids = np.unique(tids)\n",
    "    return dict((tid, timeline[tids == tid]) for tid in unique_tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1423886592: 820.13058350300003, -1419688192: 804.7894327140001, -1415489792: 804.79589456100007, -1411291392: 804.690985329}\n"
     ]
    }
   ],
   "source": [
    "timelines_by_tid = get_timelines_by_tid(j.timeline_results)\n",
    "time_by_tid = dict((tid, get_timeline_duration(timeline))\n",
    "                   for (tid, timeline) in timelines_by_tid.items())\n",
    "print(time_by_tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_thruput = j.nEvent / sum(time_by_tid.values()) * j.nThread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.94681111992 4.87727197344\n"
     ]
    }
   ],
   "source": [
    "print(avg_thruput, get_throughput(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that works, but lets try to implement it another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg_thread_time(job):\n",
    "    \"\"\"Get the thread-averaged event loop time\"\"\"\n",
    "    tids = job.timeline_results['tids']\n",
    "    unique_tids = np.unique(tids)\n",
    "    start = get_evloop_start_time(job)\n",
    "    ends = job.timeline_results['ends']\n",
    "    time = 0\n",
    "    for tid in unique_tids:\n",
    "        thread_ends = ends[tids == tid]\n",
    "        thread_end = thread_ends[-1]\n",
    "        time += (thread_end - start)*1e-9\n",
    "    return time / job.nThread\n",
    "\n",
    "def get_avg_throughput(job):\n",
    "    return job.nEvent / get_avg_thread_time(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.94681111992 4.87727197344 4.94681094052\n"
     ]
    }
   ],
   "source": [
    "print(avg_thruput, get_throughput(j), get_avg_throughput(j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
